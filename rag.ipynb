{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qqq install pip --progress-bar off\n",
    "!pip -qqq install langchain-groq==0.1.3 --progress-bar off\n",
    "!pip -qqq install langchain==0.1.17 --progress-bar off\n",
    "!pip -qqq install llama-parse==0.1.3 --progress-bar off\n",
    "!pip -qqq install qdrant-client==1.9.1  --progress-bar off\n",
    "!pip -qqq install \"unstructured[md]\"==0.13.6 --progress-bar off\n",
    "!pip -qqq install fastembed==0.2.7 --progress-bar off\n",
    "!pip -qqq install flashrank==0.2.4 --progress-bar off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "from google.colab import userdata\n",
    "from IPython.display import Markdown\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from llama_parse import LlamaParse"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
